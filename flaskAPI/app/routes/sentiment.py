from flask import Blueprint, request, jsonify
from app.models.sentiment_model import predict_sentiment
from konlpy.tag import Okt
from collections import Counter
from sentence_transformers import SentenceTransformer, util

sentiment_bp = Blueprint("sentiment", __name__)
okt = Okt()
model = SentenceTransformer("snunlp/KR-SBERT-V40K-klueNLI-augSTS")

def normalize_adjective(word, tag):
    """í˜•ìš©ì‚¬/ë™ì‚¬ë¥¼ ëª…ì‚¬ í˜•íƒœë¡œ ë³€í™˜"""
    if tag == "Noun":
        return word
    elif tag in ["Adjective", "Verb"]:
        # ì–´ê°„ ì¶”ì¶œ
        stemmed = okt.morphs(word, stem=True)[0]
        # ê¸°ë³¸ ëª…ì‚¬í™”: "ìŒ" ë˜ëŠ” "í•¨" ì¶”ê°€
        if stemmed.endswith("í•˜"):  # ì˜ˆ: ê¹¨ë—í•˜ë‹¤ â†’ ê¹¨ë—í•¨
            return stemmed + "í•¨"
        return stemmed + "ìŒ"  # ì˜ˆ: ì¢‹ë‹¤ â†’ ì¢‹ìŒ
    return word

def extract_positive_tags(text, top_k=5, threshold=0.3):
    from konlpy.tag import Okt
    from collections import Counter
    from sentence_transformers import SentenceTransformer, util
    import torch
    import re

    okt = Okt()
    model = SentenceTransformer("snunlp/KR-SBERT-V40K-klueNLI-augSTS")

    def normalize_adjective(word: str) -> str:
        word = re.sub(r"(í•˜ê³ |í•˜ë©°|í•˜ë©´ì„œ|í•˜êµ¬ìš”|í•˜ì‹­ë‹ˆë‹¤)$", "", word)
        word = re.sub(r"(í•œ|í–ˆë˜|í•˜ë˜|ìŠ¤ëŸ¬ìš´|ìŠ¤ëŸ½ë‹¤)$", "", word)
        word = re.sub(r"(ì•˜ì–´ìš”|ì—ˆì–´ìš”|í–ˆì–´ìš”|ë„¤ìš”|í–ˆë„¤ìš”|í•´ìš”|í–ˆìŠµë‹ˆë‹¤|í•´ë´¤ì–´ìš”)$", "ìŒ", word)
        return word

    # í˜•íƒœì†Œ ë¶„ì„: ëª…ì‚¬/í˜•ìš©ì‚¬ ì¤‘ì‹¬ + 2ê¸€ì ì´ìƒ
    pos_tags = okt.pos(text, stem=False)
    raw_words = [
        normalize_adjective(word) if tag == "Adjective" else word
        for word, tag in pos_tags
        if tag in {"Noun", "Adjective"} and len(word) > 1
    ]

    # ë¹ˆë„ ê³„ì‚°
    word_freq = Counter(raw_words)
    candidates = list(word_freq.keys())

    if not candidates:
        return []

    # ë²¡í„° ìƒì„±
    sentence_embedding = model.encode(text, convert_to_tensor=True)
    noun_embeddings = model.encode(candidates, convert_to_tensor=True)
    scores = util.cos_sim(sentence_embedding, noun_embeddings)[0]

    # âœ… ë„ˆë¬´ ìœ ì‚¬í•˜ê±°ë‚˜ ë„ˆë¬´ ì¼ë°˜ì ì¸ ë‹¨ì–´ëŠ” ì œê±°
    filtered = []
    for word, score in zip(candidates, scores):
        s = float(score)
        # ë„ˆë¬´ ë†’ì€ ì ìˆ˜ (ë¬¸ë§¥ ë‚´ ì¶”ìƒ ì¼ë°˜ ë‹¨ì–´), ë„ˆë¬´ ë‚®ì€ ì ìˆ˜ (ê´€ë ¨ ì—†ìŒ) â†’ ì œì™¸
        if threshold <= s <= 0.85:
            filtered.append((word, s, word_freq[word]))

    # ì •ë ¬: ìœ ì‚¬ë„ + ë¹ˆë„ ê¸°ì¤€
    filtered.sort(key=lambda x: (x[1], x[2]), reverse=True)

    return [word for word, _, _ in filtered[:top_k]]

@sentiment_bp.route("/predict", methods=["POST"])
def predict():
    data = request.get_json()
    if not data or "text" not in data:
        return jsonify({"error": "í…ìŠ¤íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400

    text = data["text"]
    sentiment = predict_sentiment(text)
    tags = extract_positive_tags(text) if sentiment["result"] == "ê¸ì • ğŸ˜Š" else []

    return jsonify({
        "text": text,
        "sentiment": sentiment,
        "tags": tags
    })
